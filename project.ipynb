{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "85e65dd126a5708a4bfedf05126b2dd2366f42efdc5cb039c58cde41fbf2f274"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WIP]\n",
    "# TO RUN THIS NOTEBOOK YOU NEED THE SOURCE FOLDER WITH THE ARTICLES I USED!\n",
    "# WILL FIND OPEN-SOURCE ARTICLES SO THAT IT CAN BE TESTED WITH THOSE\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import fitz\n",
    "import string\n",
    "import nltk\n",
    "import PyPDF2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import pandas as pd\n",
    "from functions import readPDF, processPDF, lemmatizeAndStem, toDataFrame, listOfWords, corpusOfWords, tfidfCorpus\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "\n",
    "string.punctuation += \"”\"\n",
    "string.punctuation += \"“\"\n",
    "string.punctuation += \"’\"\n",
    "string.punctuation += \"‘\"\n",
    "string.punctuation += \"``\"\n",
    "string.punctuation += \"''\"\n",
    "string.punctuation += \"|||\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the files and convert from pdf to string/dict\n",
    "articles = readPDF('sources')\n",
    "\n",
    "# Basic text-processing, tokenize and filtering\n",
    "processedArticles = processPDF(articles)\n",
    "\n",
    "\n",
    "# Gensim, LDA stuff\n",
    "dataFrame = toDataFrame(processedArticles)\n",
    "print(dataFrame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfWords = listOfWords(dataFrame)\n",
    "\n",
    "corpusOfWords = corpusOfWords(dataFrame)\n",
    "\n",
    "tfidfCorpus = tfidfCorpus(listOfWords, dataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpusOfWords, num_topics=20, id2word=listOfWords, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(tfidfCorpus, num_topics=20, id2word=listOfWords, passes=2, workers=4)\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model[corpusOfWords[3]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model_tfidf[corpusOfWords[3]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}